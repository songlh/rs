\documentclass[10pt]{article}
\usepackage{geometry}
\usepackage{amsmath}

\usepackage{url}
\addtolength{\oddsidemargin}{-.4in}
\addtolength{\evensidemargin}{-.4in}
\addtolength{\textwidth}{0.8in}

\addtolength{\topmargin}{-0.3in}
\addtolength{\textheight}{1.3in}
\usepackage[numbers, sort]{natbib}

\usepackage{paralist}
\newenvironment{ParaEnum}[0]{\begin{inparaenum}[(1)]}{\end{inparaenum}}

\title{\vspace{-.7in}\bf{Linhai Song - Research Statement\vspace{-.4in}}}
%\author{Guoliang Jin}
\date{}
\begin{document}
\maketitle\vspace{-.2in}

My main research interests are software system, program analysis, and software engineering. 
The goal of my research is to help programmers build more efficient software systems.

Everyone wants software to run fast. 
Slow and inefficient software can easily frustrate end users and cause economic loss. 
The software-inefficiency problem has already caused several highly publicized failures. 
One major source of softwareâ€™s slowness is \textit{performance bug}. 
Performance bugs are software implementation mistakes that can cause inefficient execution. 
Performance bugs cannot be optimized away by state-of-practice compilers. 
Many of them escape from in-house testing and manifest in front of end users, causing severe performance degradation and huge energy waste in the field. 
Performance bugs are becoming more critical, with the increasing complexity of modern software and workload, 
the meager increases of single-core hardware performance, 
and pressing energy concerns. 
It is urgent to combat performance bugs.

My PhD research has mainly focused on performance bugs. 
My experience spans different
stages of combating performance bugs: real-world bug understanding, bug detection,
compiler optimization, and failure diagnosis.
In particular, I conduct the first characteristics study on 110 real-world performance bugs 
randomly collected from 5 representative open-source software suites~\cite{jin12perfbug}.
I build a static performance bug detection tool suite, based on extracted efficiency rules from fixed performance bugs~\cite{jin12perfbug}, 
and help build a dynamic performance bug detection tool for inefficient nested loops~\cite{Nistor13ICSE}. 
These two techniques find hundreds of previously unknown performance bugs, many of which have already been confirmed and fixed by developers. 
I design three source-to-source compiler optimizations to transparently eliminate performance bugs in 
parallel applications, which offload computation to Intel Xeon Phi manycore coprocessor~\cite{Song14MICRO}, 
and this work won MICRO'14 best paper runner up. 
I explore how to apply statistical debugging to performance failure diagnosis~\cite{Song14OOPSLA}, 
and design a series of static-dynamic hybrid analysis routines to provide more detailed diagnosis information for inefficient loops~\cite{Song16PLDI}.    

Besides combating performance bugs, 
I also work on a concurrency bug fixing system~\cite{jin11afix}, 
which won a SIGPLAN CACM research highlight nomination~\cite{afixnom}, 
and help study change histories of critical sections in open-source software~\cite{Gu15FSE} 
to provide better understanding of synchronization challenges faced by real-world developers.



\section{Dissertation Research}

\paragraph{Real-world Performance Bug Understanding.}
Like functional bugs, research on performance bugs should also be guided by empirical studies. 
Poor understanding of performance bugs is part of the causes of today's performance bug problem. 
In order to improve the understanding of real-world performance bugs, 
I co-lead the first, to the best of our knowledge, 
empirical study on 110 real-world performance bugs randomly sampled from five open-source software suites~\cite{jin12perfbug}. 
Following the lifetime of performance bugs, 
our study is mainly performed in four dimensions. 
We study the root causes of performance bugs, 
how they are introduced, how to expose them, and how to fix them. 
The main findings of our study include that 
(1) performance bugs have dominating root causes and fix strategies, which are highly correlated with each other; 
(2) workload mismatch and misunderstanding of APIs' performance features are two major reasons why performance bugs are introduced; 
and (3) around half of the studied performance bugs require inputs with both special features and large scales to manifest. 

Our empirical study can guide future research on performance bugs, 
and it has already motivated our own bug detection and diagnosis projects.


\paragraph{Static/Dynamic Performance Bug Detection.}

Inspired by our empirical study, we hypothesize that 
efficiency rules widely exist in software, 
rule violations can be statically checked, 
and violations also widely exist. 
To test our hypothesis, we manually inspect final patches of fixed performance bugs from Apache, Mozilla, and MySQL in our studied performance bug set, 
extract efficiency rules from 25 bug patches, 
and implement static checkers to detect rules' violations~\cite{jin12perfbug}. 
In total, our static checkers find 332 previously unknown performance bugs from the latest versions of Apache, Mozilla, and MySQL. 
Among them, 101 were inherited from the original buggy versions where final patches are applied. 
Tools are needed to help developers automatically and systematically find all similar bugs. 
12 new bugs were introduced later. 
Tools are needed to help developers avoid making the same mistakes repeatedly. 
219 new bugs are found by cross-application checking. There are generic rules among different software. 
We report some of identified bugs to developers. 
77 reported bugs have already been confirmed by developers, including 15 reported bugs already fixed by developers. 
Overall, all our hypotheses are verified by our experimental results. Rule-based performance-bug detection is a promising direction.

Our empirical study also finds that 90\% performance bugs involve loops, 
and 50\% performance bugs involve at least two-level of loops. 
Motivated by this finding, I help a fellow graduate student build a novel automated test oracle named Toddler~\cite{Nistor13ICSE}, 
which enables testings for performance bugs to use the well established and automated process of testing for functional bugs. 
Using Toddler, we find 42 new bugs in six Java projects: 
Ant, Google Core Libraries, JUnit, Apache Collections, JDK, and JFreeChart. 
Based on our bug reports, developers so far fixed 10 bugs and confirmed 6 more as real bugs.


\paragraph{Source-to-Source Compiler Optimization.}
Xeon Phi coprocessors are introduced by Intel recently as new members of the manycore family. 
Compared with GPU, Xeon Phi coprocessors are easier to program, 
since they provide x86 compatibility and support many different programming models. 
In order to offload existing parallel loops, developers just need to add simple pragmas. 
However, our recent experience shows that simply adding pragmas does not give performance, 
and too many performance bugs contained in offloaded parallel loops. 

After careful investigation, we design three source-to-source compiler optimizations to 
transparently eliminate performance bugs contained in offloaded parallel loops~\cite{Song14MICRO}. 
The first optimization, data streaming, is designed to reduce the overhead of transferring data between CPUs and coprocessors. 
The optimization automatically transfers offloaded codes to stream data to and from coprocessors, which overlaps data transfers 
with computation to hide data transfer overhead and reuse memory on coprocessors. 
The second optimization, regularization, is design to handle loops with irregular memory accesses. 
This optimization identifies irregular memory access patterns inside a offloaded loop and re-arranges the order of computations to regularize memory accesses. 
It enables data streaming and vectorization for manycore processors in the presence of irregular memory accesses. 
The last optimization is designed to support the efficient transfer for large pointer-based data structures between CPUs and coprocessors. 
An augmented design of pointers is introduced for fast translating pointers between their CPU and coprocessor memory addresses. 
The designed optimizations can benefit 9 out of 12 benchmarks in the experiments, and improve the performance by 1.16x - 52.21x. 
This work won MICRO'14 best paper runner up. 




\paragraph{Performance Failure Diagnosis.}

Due to the preliminary tool support, many performance bugs escape from in-house performance testing and manifest in front of end users. 
After users report performance bugs, developers need to diagnose them and fix them.
Diagnosing user-reported performance failure is another key aspect of fighting performance bugs. 

We investigate the feasibility and design space to apply statistical debugging to performance failure diagnosis~\cite{Song14OOPSLA}.
After studying 65 user-reported performance bugs in our bug set, 
we find that majority of performance bugs are observed through comparison, 
and many user-filed performance bug reports contain not only bad inputs, but also similar and good inputs.
Statistical debugging is a natural fix for user-reported performance bugs. 
We evaluate three types of widely used predicates and two representative statistical models. 
Our evaluation results show that branch predicate plus two statistical models can effectively diagnose user-reported performance failure. 
Basic model can help diagnose performance failure caused by wrong branch decision, and $\Delta $LDA model can identify inefficient loops.  
We apply sampling to performance failure diagnosis. Our experimental results show that
special nature of loop-related performance bugs allows sampling to lower runtime overhead without sacrificing diagnosis latency, 
and this is very different from functional failure diagnosis.

We build LDoctor~\cite{Song16PLDI} to further provide fine-grained diagnosis information for inefficient loops through two steps. 
We first figure out a root-cause taxonomy for common inefficient loops through a comprehensive study on 45 inefficient loops. 
Our taxonomy contains two major categories: resultless and redundancy, and several subcategories. 
Guided by our taxonomy, we then design a series of analysis for inefficient loops. 
Our analysis 
focuses its checking on suspicious loops pointed out by statistical debugging, 
hybridizes static and dynamic analysis to balance accuracy and performance, 
and relies on sampling and other designed optimization to further lower runtime overhead. 
We evaluate LDoctor by using 18 real-world inefficient loops. 
Evaluation results show that LDoctor can cover most root cause subcategories, 
report few false positives, and bring a low runtime overhead. 



\section{Future Research}

The goal of my research is to improve performance of various types of software systems. 
My future projects can be conducted along two lines. 
One direction is to combat studied performance bugs in different aspects from what I have already done, 
like on-line workload monitoring and performance test input generation. 
The other direction is to explore performance problems in other areas. 
Although the performance bugs in our study provide a good coverage of real-world performance problems, 
there are still uncovered categories, 
like performance problems in scientific computation, distributed systems, mobile and web applications. 
The following are some immediate research opportunities: 

\paragraph{On-line Algorithmic Profiling.}
Many performance bugs in our study are caused by conducting computation in superlinear complexity. 
There are two possible reasons why these performance bugs are introduced. 
In one case, under the assumption that workload would be small, developers choose to use superlinear algorithms. 
In the other case, unnoticed superlinear codes escape from the testing process, due to the small size of test inputs. 
On-line algorithmic monitoring can detect performance bugs in both of these two situations. 
Previous work on algorithmic profiling or monitoring will bring more than 10X runtime overhead, 
which cannot be tolerated in production run. 
How to build a tool which can collect runtime information in a reasonable overhead from deployed software 
and infer approximate complexity remains an open question. 

\paragraph{Test Input Generation for Performance Bugs.}
Our empirical study shows that almost half of studied performance bugs need inputs with both special features and large scales to manifest. 
Existing techniques are designed to generate inputs with good code coverage and focus only on special features.
How to extend existing input generation techniques with emphasis on large scales remains an open issue. 
Another important problem during performance testing is to automatically judge whether a problem bug has occurred. 
How to leverage existing dynamic performance bug detection techniques to build test oracles for performance bugs also remains an open issue.

\paragraph{Tool Support for Tuning Floating-point Applications.}
Floating-point arithmetic is used in a wide variety of applications, 
including high-performance computing, graphics and finance. 
Many programming language provides two types of floating-point numbers: double and float. 
Double numbers are represented by using more digits, and they are more accurate than float numbers. 
Insufficient accuracy may accumulate during computation, 
and make programs instable or generate final results with intolerable large relative errors. 
However, float numbers can be processed much faster than double numbers, 
because float numbers bring less memory traffic, 
and after vectorization optimization, one SIMD instruction can process one time more float numbers than double numbers. 
Choosing between float numbers and double numbers must balance precision and performance. 
I would like to provide tool support to help developers optimize floating-point arithmetic programs under given precision bounds. 

\paragraph{Empirical Study on  Performance Problems in Real-world Web Applications.}
Web applications are highly interactive. 
Latency of event handlers in web applications is more important than the whole execution time. 
This feature makes performance problems in web applications different from performance bugs I have studied. 
Web applications are popular. 
Optimizing web applications and combating performance bugs in web applications are important. 
I would like to study performance problems in open-source web applications, 
and provide better understanding for the root causes, 
exposing conditions, and fix strategies of these performance problems, 
leveraging my previous experience of bug study. 







\newpage
\bibliographystyle{plainyr-rev}
\bibliography{rs}
\end{document}
